{
    "filename": "Syllabus.pdf",
    "file_type": "syllabus",
    "extracted_at": "20251108_184836",
    "text_length": 5077,
    "text": "--- Page 1 ---\n NATURAL LANGUAGE PROCESSING Course Code 22AIM53 CIE Marks 50 L:T:P:S 3:0:0:0 SEE Marks 50 Hrs. / Week 3 Total Marks 100 Credits 03 Exam Hours 03 Course outcomes: At the end of the course, the student will be able to: 22AIM53.1 Understand basics of linguistics, probability and statistics associated with NLP. 22AIM53.2 Analyze the semantic of natural language. \n22AIM53.3 Design an end-to-end NLP application by integrating preprocessing, feature extraction, and model-building techniques. 22AIM53.4 Evaluate the performance of advanced transformer models (e.g., BERT, GPT-3) in various NLP tasks such as text classification, summarization, and topic modeling. 22AIM53.5 Demonstrate the working of sequence models for text processing. 22AIM53.6 Implement the NLP applications on emerging trends with ethical implications. Mapping of Course Outcomes to Program Outcomes and Program Specific Outcomes: \n PO1PO2 PO3PO4 PO5 PO6 PO7 PO8 PO9 PO10 PO11 PO12 PSO1PSO2 22AIM53.1 2 - - - - - - - - - - - --- - 22AIM53.2 - 3 - - - - - - - - - 2 3 2 22AIM53.3 - - 3 - - - - - - - - 2 3 2 22AIM53.4 - - 3 - \n - - - - - - 2 3 2 22AIM53.5 - - 3 - \n - - - - - - 2 3 2 22AIM53.6 - - 3 - 3 - - 2 \n - - 2 3 2 MODULE-1 Natural Language Processing 22AIM53.1 8 Hours Components - Basics of Linguistics and Probability and Statistics – Words-Tokenization-Morphology: Inflectional Morphology - Derivational Morphology. Finite-State Morphological Parsing - Porter Stemmer. Case Study Case studies of NLP applications in various industries. Text Book Text Book 1: Ch 2,3,4 MODULE-2 Semantic Analysis 22AIM53.2 8 Hours Representing Meaning-Meaning Structure of Language-First Order Predicate Calculus Representing Linguistically Relevant Concepts -Syntax-Driven Semantic Analysis - Semantic Attachments -Syntax- Driven Analyzer. Robust Analysis - Lexemes and Their Senses - Internal Structure - Word Sense Disambiguation -Information Retrieval Text Book Text Book 1: 13,14,18 MODULE-3 WORD REPRESENTATION AND PART OF SPEECH  22AIM53.2, 22AIM53.3 8 Hours \nN-grams and Language models –Smoothing- Evaluating Language Model -Text classification- Naïve Bayes classifier –- Vector Semantics – TF-IDF – Word Embeddings: Word2Vec, Glove and Fast Text-Part of Speech – Part of Speech Tagging -Named Entities –Named Entity Tagging-Conditional Random Fields(CRFs). \nText Book Text Book 1: Ch 4,5,10,17,19 MODULE-4 Transformer and Topic Models 22AIM53.4, 22AIM53.5 8 Hours \nIntroduction to transformer architecture-BERT (Bidirectional Encoder Representations from Transformers)-GPT-3 (Generative Pre-trained Transformer 3)-Fine-tuning transformer models for NLP tasks. Topic Modeling: Introduction to topic modeling-Latent Dirichlet Allocation (LDA)-Non-Negative Matrix Factorization (NMF). Text Book Text Book 1:16,18 \n\n--- Page 2 ---\nMODULE-5 Applications and Future Directions in NLP 22AIM53.5, 22AIM53.6 8 Hours \nApplications and   Implementation   of   NLP:   Sentiment   Analysis   -   Text   Classification-   Text  \n\n--- Page 3 ---\n Summarization- Named Entity Recognition code- Chatbots and Dialogue systems. Future Trends in NLP-Emerging trends and research areas-AI-driven NLP tools and services. \n \nCase Study Using NLP for Healthcare summaries Text Book Text Book 1: 17-20 \n CIE Assessment Pattern (50 Marks – Theory) \n \n RBT Levels Test Assessment(s) * MCQ \n 25 15 10 L1 Remember 5 \n 5 L2 Understand 5 - 5 L3 Apply 10 5 \n L4 Analyze 5 10 \n L5 Evaluate - - \n L6 Create - - \n \n*Assessments are to be selected from the assessment list attached to Appendix A.. \n \nSEE Assessment Pattern (50 Marks – Theory) \n RBT Levels Exam Marks Distribution (50) \n \n L1 Remember 10 \n L2 Understand 10 \n L3 Apply 20 \n L4 Analyze 10 \n L5 Evaluate - \n L6 Create - Suggested Learning Resources: Text Books: \n1)\n \nDaniel\n \nJurafsky\n \nand\n \nJames\n \nH.\n \nMartin,\n \n“Speech\n \nand\n \nLanguage\n \nProcessing:\n \nAn\n \nIntroduction\n \nto\n Natural Language Processing, Computational Linguistics and Speech Recognition (Prentice Hall Series in Artificial Intelligence), 2017. ISBN: 0133252930, 9780133252934 \n2)\n \nJacob\n \nEisenstein.\n \n“Natural\n \nLanguage\n \nProcessing\n \n“,\n \nMIT\n \nPress,\n \n2019.\n \nISBN:\n \n9780262042840\n https://web.stanford.edu/~jurafsky/slp3/( Updated Text book content available link) Reference Books: \n1)\n \nSamuel\n \nBurns\n \n“Natural\n \nLanguage\n \nProcessing:\n \nA\n \nQuick\n \nIntroduction\n \nto\n \nNLP\n \nwith\n \nPython\n \nand\n \nNLTK,\n 2019. \n2)\n \nChristopher\n \nManning,\n \n“Foundations\n \nof\n \nStatistical\n \nNatural\n \nLanguage\n \nProcessing”,\n \nMIT\n \nPress,\n \n2009\n Web links and Video Lectures (e-Resources): \n●\n https://archive.nptel.ac.in/courses/106/106/106106211/ \n●\n https://www.nptelvideos.com/course.php?id=424 \n●\n https://www.youtube.com/watch?v=rmVRLeJRkl4 \nActivity-Based Learning (Suggested Activities in Class)/ Practical Based learning \n●\n \nOnline\n \nClass\n \nusing\n \nJeopardy\n \n●\n \nContents\n \nrelated\n \nactivities\n \n(Activity-based\n \ndiscussions)\n \n\u0000\n \nFor\n \nactive\n \nparticipation\n \nof\n \nstudents,\n \ninstruct\n \nthe\n \nstudents\n \nto\n \nread\n \nresearch\n \ntopics\n \non\n \nNLP\n \n\u0000\n \nClass\n \nPresentation.",
    "preview": "--- Page 1 ---\n NATURAL LANGUAGE PROCESSING Course Code 22AIM53 CIE Marks 50 L:T:P:S 3:0:0:0 SEE Marks 50 Hrs. / Week 3 Total Marks 100 Credits 03 Exam Hours 03 Course outcomes: At the end of the course, the student will be able to: 22AIM53.1 Understand basics of linguistics, probability and statistics associated with NLP. 22AIM53.2 Analyze the semantic of natural language. \n22AIM53.3 Design an end-to-end NLP application by integrating preprocessing, feature extraction, and model-building techni"
}